{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6317956b-1d2d-4991-97c1-2c05bfeb3d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taken from https://www.kaggle.com/code/suvroo/complete-nlp-pipeline#RoPE-(Robust-Positional-Embeddings)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# research-methods/imdb/IMDB_dataset.csv\n",
    "df = pd.read_csv('IMDB_dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd15eef8-afb1-45c5-8316-3d04bef62664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efeb1bb-dc34-4c0a-b482-a66c035650e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3784b-f6d0-4d2f-b744-e90cb4ed6855",
   "metadata": {},
   "source": [
    "Stopwords include negating words, so removing them would remove important context from texts.\n",
    "\n",
    "Disabled stopwords removoal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "825bb43d-d998-46c2-b9fb-d69cc0754025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1d5af2-1862-4419-bb57-7f82594171bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text column name:review\n",
      "Clean dataset's text. started with 49582 rows, after cleaning: 49582\n"
     ]
    }
   ],
   "source": [
    "def remove_tags(raw_text):\n",
    "    cleaned_text = re.sub(re.compile('<.*?>'), '', raw_text)\n",
    "    return cleaned_text\n",
    "    \n",
    "\n",
    "def clean_text_column(df, text_col_name):\n",
    "    \"\"\"Clean the text column by removing rows with empty text while retaining specific symbols (!, ?, .).\"\"\"\n",
    "    # Drop rows with missing or empty text\n",
    "    start_len = len(df)\n",
    "    df = df[df[text_col_name].notnull()]  # Remove NaN values\n",
    "    df = df[df[text_col_name].str.strip().astype(bool)]  # Remove empty strings\n",
    "\n",
    "    # Clean text by removing unusual symbols, non english text, except !, ?, .\n",
    "    def clean_text(text):\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r\"^[-a-zA-Z0-9@:%._\\\\+~#=]{1,256}\\\\.[a-zA-Z0-9()]{1,6}\\\\b(?:[-a-zA-Z0-9()@:%_\\\\+.~#?&\\\\/=]*)$\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s!?.,]', '', text)  # Remove non-alphanumeric characters except !, ?, .\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "        return text.strip()  # Strip leading/trailing spaces\n",
    "\n",
    "    df[text_col_name] = df[text_col_name].apply(clean_text)\n",
    "\n",
    "    # Define a function to filter out rows with insufficient content\n",
    "    def has_valid_content(text):\n",
    "        # Remove rows that only contain symbols like !, ?, or .\n",
    "        if re.fullmatch(r'[!?.,\\s]*', text):\n",
    "            return False\n",
    "        # Removes rows with less than 4 chars\n",
    "        if len(text.strip()) < 4:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    # Apply the filter\n",
    "    df = df[df[text_col_name].apply(has_valid_content)]\n",
    "    cur_len = len(df)\n",
    "    print(f\"Clean dataset's text. started with {start_len} rows, after cleaning: {cur_len}\")\n",
    "    return df\n",
    "\n",
    "text_col_name = 'review'\n",
    "\n",
    "# Remove HTML tags\n",
    "df[text_col_name] = df[text_col_name].apply(remove_tags)\n",
    "\n",
    "# Clean text column\n",
    "print(f'text column name:{text_col_name}')\n",
    "df = clean_text_column(df, text_col_name)\n",
    "\n",
    "# Disabled stopwords removal\n",
    "# sw_list = stopwords.words('english')\n",
    "# df['review'] = df['review'].apply(lambda x: [item for item in x.split() if item not in sw_list]).apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83d4001-a7af-4068-8e67-1691f82096aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['sentiment'].str.lower()\n",
    "df['label'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5983c9c-9803-4835-8dd3-04c6a88b22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"preprocessed_imdb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3aaae7-970f-4f5c-bd36-201bfe36be61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86e4e8bd-7676-46c7-80bd-538a13c2c494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved /sise/home/saarbu/research-methods/imdb/data_cleaned_from_nan_embeddings_with_clusters.csv with columns: ['review', 'label', 'cluster']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "# ── 1.  set your paths ──────────────────────────────────────────────────────────\n",
    "base_dir = Path(\"/sise/home/saarbu/research-methods/imdb\")\n",
    "feature_imp_path = base_dir / \"clustering results\" / \"feature_importance_scores.csv\"\n",
    "embeddings_path  = base_dir / \"full_embeddings_cleaned.parquet\"\n",
    "sentiment_path   = base_dir / \"data_cleaned_from_nan_embeddings.csv\"\n",
    "out_path         = base_dir / \"data_cleaned_from_nan_embeddings_with_clusters.csv\"\n",
    "\n",
    "# ── 2.  load feature-importance file & grab top-50 indices ─────────────────────\n",
    "imp_df = pd.read_csv(feature_imp_path)\n",
    "top50_idx = (\n",
    "    imp_df.sort_values(\"importance_score\", ascending=False)\n",
    "          .head(50)[\"feature_index\"]\n",
    "          .astype(int)\n",
    "          .tolist()\n",
    ")\n",
    "\n",
    "# ── 3.  load embeddings and flatten if stored as a list column ─────────────────\n",
    "emb_df = pd.read_parquet(embeddings_path)\n",
    "\n",
    "# if the parquet has a single “embedding” column with Python lists, expand it\n",
    "if emb_df.shape[1] == 1:\n",
    "    emb_df = pd.DataFrame(emb_df.iloc[:, 0].tolist())\n",
    "\n",
    "# ensure column names are integers 0…1535 so we can index by number\n",
    "emb_df.columns = emb_df.columns.astype(int)\n",
    "\n",
    "# ── 4.  build the feature matrix with the 50 most important dimensions ─────────\n",
    "X = emb_df[top50_idx].values\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# ── 5.  cluster (k = 40) ────────────────────────────────────────────────────────\n",
    "kmeans   = KMeans(n_clusters=40, init=\"k-means++\", n_init=10, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)          # shape = (3046,)\n",
    "\n",
    "# ── 6.  append cluster labels to the sentiment / text file ─────────────────────\n",
    "sent_df = pd.read_csv(sentiment_path)\n",
    "assert len(sent_df) == len(clusters), \"Row count mismatch between sentiment file and embeddings!\"\n",
    "\n",
    "sent_df = sent_df.reset_index(drop=True)  # just to be safe\n",
    "sent_df[\"cluster\"] = clusters\n",
    "\n",
    "# ── 7. keep only requested columns & save ──────────────────────────────────────\n",
    "cols_needed = [\"review\", \"label\", \"cluster\"]\n",
    "missing = [c for c in cols_needed if c not in sent_df.columns]\n",
    "if missing:\n",
    "    raise KeyError(f\"Column(s) not found in sentiment file: {missing}\")\n",
    "\n",
    "sent_df[cols_needed].to_csv(out_path, index=False)\n",
    "print(f\"✓ Saved {out_path} with columns: {cols_needed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb97af17-2e83-4691-b2ba-eddd174be95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
